
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Deep Learning for Microscopy Image Analysis &#8212; QI 2024 Analysis Lab Manual</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Lab05_DL4MIA_Zero_N2V_StarDist_CellPose2';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3D Image Analysis" href="Lab06_3D_Image_Analysis.html" />
    <link rel="prev" title="Segmentation and Pixel Classification" href="Lab04_ML-based_Segmentation_and_Classification.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
   
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/image001.png" class="logo__image only-light" alt="QI 2024 Analysis Lab Manual - Home"/>
    <script>document.write(`<img src="_static/image001.png" class="logo__image only-dark" alt="QI 2024 Analysis Lab Manual - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to QI 2024
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Lab03_Image_Correction_and_Intensity_Measurements.html">Image Correction and Intensity Measurements</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lab04_ML-based_Segmentation_and_Classification.html">Segmentation and Pixel Classification</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Deep Learning for Microscopy Image Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lab06_3D_Image_Analysis.html">3D Image Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lab07_Image_Time_Series_Analysis.html">Image Time Series Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Additional Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/bethac07/qi_2024_analysis_lab_manual" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/bethac07/qi_2024_analysis_lab_manual/edit/main/qi_2024_analysis_lab_manual/Lab05_DL4MIA_Zero_N2V_StarDist_CellPose2.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/bethac07/qi_2024_analysis_lab_manual/issues/new?title=Issue%20on%20page%20%2FLab05_DL4MIA_Zero_N2V_StarDist_CellPose2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Lab05_DL4MIA_Zero_N2V_StarDist_CellPose2.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Deep Learning for Microscopy Image Analysis</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview"><strong>Overview</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1-remind-yourself-about-what-weve-heard-in-the-lecture"><strong>Exercise 1: Remind yourself about what we‚Äôve heard in the lecture</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-play-with-cellpose"><strong>Exercise 2: Play with CellPose</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#human-in-the-loop-retraining">Human-in-the-loop retraining</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-the-image-restoration-functions">Using the image restoration functions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-first-steps-with-google-colab-dont-waste-too-much-time-here"><strong>Exercise 3: First steps with Google Colab (don‚Äôt waste too much time here‚Ä¶)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-4-first-steps-with-zerocostdl4mic"><strong>Exercise 4: First steps with ZeroCostDL4Mic</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-5-image-denoising-with-noise2void-in-zero"><strong>Exercise 5: Image Denoising with Noise2Void (in ‚ÄúZero‚Äù)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bonus-exercise-use-fijis-noise2void-plugin"><strong>Bonus Exercise: Use Fiji‚Äôs Noise2Void Plugin</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bonus-exercise-image-segmentation-with-stardist-in-zero"><strong>Bonus Exercise: Image Segmentation with StarDist (in ‚ÄúZero‚Äù)</strong></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="deep-learning-for-microscopy-image-analysis">
<h1>Deep Learning for Microscopy Image Analysis<a class="headerlink" href="#deep-learning-for-microscopy-image-analysis" title="Link to this heading">#</a></h1>
<p><em>Lab authors: Damian Dalle Nogare and Florian Jug</em> .</p>
<p><small>This file last updated 2024-04-04.</small></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Notes</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">spreadsheet</span> <span class="n">on</span> <span class="n">what</span> <span class="n">we</span> <span class="n">might</span> <span class="n">want</span> <span class="n">to</span> <span class="n">update</span><span class="p">:</span>

<span class="n">Think</span> <span class="n">about</span> <span class="n">adding</span> <span class="n">some</span><span class="o">/</span><span class="nb">all</span> <span class="n">of</span> <span class="o">-</span> <span class="n">BioimageIO</span><span class="p">,</span> <span class="n">Piximi</span><span class="p">,</span> <span class="n">Accessing</span> <span class="n">Cellpose</span> <span class="n">via</span> <span class="n">BAND</span>
</pre></div>
</div>
<hr class="docutils" />
<section id="learning-objectives">
<h2>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Appreciate how Neural Networks are trained</p></li>
<li><p>Segmentation with Cellpose</p></li>
<li><p>Learn how to get to and use Google Colab</p></li>
<li><p>Denoising with Noise2Void in ‚ÄúZero‚Äù</p></li>
<li><p>Bonus: Use Noise2Void in Fiji</p></li>
<li><p>Bonus: Segmentation with StarDist in ‚ÄúZero‚Äù</p></li>
</ul>
<p>Lab Data: <a class="reference external" href="https://bit.ly/3uEFiKg"><u>https://bit.ly/3uEFiKg</u></a></p>
</section>
<section id="overview">
<h2><strong>Overview</strong><a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p>Neural networks can do useful things. Their deployment within
user-friendly tools is, unfortunately, lacking behind. Hence, methods we
would like to apply to our data are not available in Fiji or ilastik<span id="id1">[<a class="reference internal" href="bibliography.html#id8" title="Stuart Berg, Dominik Kutra, Thorben Kroeger, Christoph N Straehle, Bernhard X Kausler, Carsten Haubold, Martin Schiegg, Janez Ales, Thorsten Beier, Markus Rudy, Kemal Eren, Jaime I Cervantes, Buote Xu, Fynn Beuttenmueller, Adrian Wolny, Chong Zhang, Ullrich Koethe, Fred A Hamprecht, and Anna Kreshuk. Ilastik: interactive machine learning for (bio)image analysis. Nat. Methods, 16(12):1226‚Äì1232, December 2019.">4</a>]</span>
quite yet. The latest methods can only be used by the ones ‚Äúbrave‚Äù
enough to expose themselves to some amount of computer source code‚Ä¶</p>
<p>Today we will all be brave! üòä</p>
<p>I‚Äôm very much looking forward to hearing about your successes and
struggles tomorrow during the Q&amp;A session. Now, please take a seat, open
a browser, and buckle up.</p>
</section>
<section id="exercise-1-remind-yourself-about-what-weve-heard-in-the-lecture">
<h2><strong>Exercise 1: Remind yourself about what we‚Äôve heard in the lecture</strong><a class="headerlink" href="#exercise-1-remind-yourself-about-what-weve-heard-in-the-lecture" title="Link to this heading">#</a></h2>
<ol class="arabic">
<li><p>Visit
<a class="reference external" href="https://playground.tensorflow.org"><u>https://playground.tensorflow.org</u></a>
and look around. What terms did you hear before, what is new, and
what is confusing?</p></li>
<li><p>Please try to:</p>
<p>a.  On the classification example that looks like a tiny
checkerboard, try to get a test loss of 0.001 or less.<br />
<img alt="_images/image11.png" src="_images/image11.png" /><img alt="_images/image4.png" src="_images/image4.png" /></p>
<p>b.  For the spiral-shaped classification example, try to find a
network architecture with the smallest amount of nodes (neurons)
that will drop below 0.01 (1%) test error.<br />
<img alt="_images/image13.png" src="_images/image13.png" />
<img alt="_images/image8.png" src="_images/image8.png" /></p>
<p>c.  Now switch from ‚ÄòClassification‚Äô to ‚ÄòRegression‚Äô. What is going
on here? Can you figure out how regression is different from
classification?<br />
<img alt="_images/image6.png" src="_images/image6.png" /></p>
<p>d.  Some other things to try if you feel it‚Ä¶</p>
<ul class="simple">
<li><p>Add some noise to your data. What changes? Why?</p></li>
<li><p>Try to find a setup that overfits. How do you identify overfitting?<br />
<img alt="_images/image14.png" src="_images/image14.png" /></p></li>
</ul>
<p>e.  All the important terms and concepts wrt. to training and
validation are somewhere on this one page. Check if there is
anything that makes no sense to you and ask us</p>
</li>
</ol>
</section>
<section id="exercise-2-play-with-cellpose">
<h2><strong>Exercise 2: Play with CellPose</strong><a class="headerlink" href="#exercise-2-play-with-cellpose" title="Link to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Once back home, you will need this link to get started:
<a class="reference external" href="https://cellpose.readthedocs.io/en/latest/installation.html"><u>https://cellpose.readthedocs.io/en/latest/installation.html</u></a></p>
</div>
<p>Here, at QI, we have taken this annoying step for you already. Hence,
you will find Cellpose pre-installed on the lab computers. To start it,
go to the Windows search next to the start menu, and type ‚Äúanaconda‚Äù.
Pick and start the option ‚Äúanaconda prompt‚Äù.</p>
<p>Once this is opened, type in those two comments (the stuff after
‚Äú<strong>&gt;</strong>‚Äù):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="n">conda</span> <span class="n">activate</span> <span class="n">cellpose</span>  
<span class="p">(</span><span class="n">cellpose</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">cellpose</span>
</pre></div>
</div>
<p>You should now see something like
this:<img alt="_images/cellpose_gui.png" src="_images/cellpose_gui.png" /></p>
<p>Open the file <code class="docutils literal notranslate"><span class="pre">easy\001_img.tif</span></code> by dragging it onto the open window.
You can find this file in the folder ‚ÄòDL4MIA‚Äô in the Lab Data share, or
download it directly via</p>
<p><a class="reference external" href="https://drive.google.com/drive/folders/1BgoUf1f-QfcFNIsppdzTCjehkCAntbyc?usp=share_link">https://drive.google.com/drive/folders/1BgoUf1f-QfcFNIsppdzTCjehkCAntbyc?usp=share_link</a></p>
<p>We need to tell cellpose (roughly) how large our objects are (you can do
so via the <code class="docutils literal notranslate"><span class="pre">cell</span> <span class="pre">diameter</span></code>) field. How might we estimate this? Keep in
mind that this diameter must be reported in pixels.</p>
<p>You can now segment this image by selecting one of the pre-trained
models from within the <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">zoo</span></code> box. Try segmenting this image using
the <code class="docutils literal notranslate"><span class="pre">cyto</span></code> model. How good are the results?</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>You can toggle the visibility of segmentation masks on and off
by hitting ‚Äò<strong>x</strong>‚Äô on your keyboard. Similarly, you can toggle cell
outlines with the keyboard shortcut ‚Äò<strong>z</strong>‚Äô. Alternatively you can do so
in the <code class="docutils literal notranslate"><span class="pre">Drawing</span></code> tab.</p>
</div>
<p>How well did cellpose segment your image? Where (if anywhere) did it
fail? Try some different models from the model zoo box. Do any of these
work better? Worse? Why might that be?</p>
<p>Let‚Äôs now try some more challenging data. From the link above, or from
the DL4MIA folder in the lab data share, download the entire folder
named ‚Äòhard‚Äô, and place it somewhere convenient (like the desktop).</p>
<p>From within this folder, open the ‚Äòtest‚Äô folder and drag the file
test_img.tif to cellpose to open it. Try segmenting it as well as
possible. Can you find setting and a model that work perfectly?</p>
<p>Spoiler, none of the models are perfectly suited to this data, but we
can iteratively retrain a model from within the Cellpose GUI‚Ä¶
interested? Ok, let‚Äôs do it! üôÇ</p>
<section id="human-in-the-loop-retraining">
<h3>Human-in-the-loop retraining<a class="headerlink" href="#human-in-the-loop-retraining" title="Link to this heading">#</a></h3>
<p>In the ‚Äòhard‚Äô folder you download earlier you will find a folder called
‚Äòtrain‚Äô. In this folder you will find a number of images. Open the image
104_img.tif‚Äô in cellpose. Note that we are not going to train a model
from scratch, instead we are going to finetune one of the existing
models (ideally starting from one that does a pretty good job already).
Choose the model that you think gave you the best segmentations in the
previous part of this exercise and apply it to this image.</p>
<p>We are going to iteratively finetune this model, one image at a time.
Once the current image is segmented well, we will open another one and
repeat until results are (hopefully) making us happy! Here a little
sketch:</p>
<p>Everytime we see a result, you can correct the segmentation errors by
redrawing some of the segmentation masks. The corrected image can then
be used to further finetune (retrain) the model.</p>
<p>You can correct errors in one of two ways:</p>
<ol class="arabic simple">
<li><p>Delete a mask by holding down the ‚Äòcontrol‚Äô key and clicking on it.</p></li>
<li><p>Draw a new mask by right-clicking anywhere in the image and tracing
an outline, ending where you began to draw.</p></li>
</ol>
<p>Try correcting some of the segmentations. It might be easier if you
switch between masks and outlines (use ‚Äòz‚Äô and ‚Äòx‚Äô as explained before).</p>
<p>Once you are happy with your corrected masks, take a look in the folder
containing all of the training images. You will notice there is a new
file there, called ‚Äòhard\train\104_img_seg.npy‚Äô. This contains your
corrected segmentation and will become a new bit of ground truth used
during finetuning the model. But‚Ä¶ how do you start this finetuning step?</p>
<p>In Cellpose, start: `models ‚Üí<br />
train new model with images and masks in folder‚Äô.</p>
<p>You should see a window like this one:</p>
<img alt="_images/cellpose_training_gui.png" src="_images/cellpose_training_gui.png" />
<p>First, we need to select which initial model to use (in the screenshot
above, we are retraining the <code class="docutils literal notranslate"><span class="pre">cyto</span></code> model (but of course you may choose
to retrain any available model). You can, and should, give your new
model a name. You can also see which (corrected) images you are going to
retrain the model on under ‚Äòfilenames‚Äô, and the number of masks that
will be used for retraining in that image. Click OK whenever you are
ready to retrain and finetune the selected model!</p>
<p>During training you should see something like the following if you check the
console (where you started cellpose from). What is going on here? Remember
back the lecture when we discussed training steps and epochs.
<img alt="_images/cellpose_training_output.png" src="_images/cellpose_training_output.png" /></p>
<p>Once done, Cellpose will open the next image in the folder and
automatically use the freshly finetuned model to segment it (NOTE: in cellpose
3 there seems to be a bug where the new model is not being used to segment
the newly loaded image. If you notice the segmentation isn‚Äôt very good, manually
select your newly trained model under the ‚Äúother models‚Äù dropdown and run it).
You can now repeat this process as often as needed. Cellpose will in each iteration
finetune the same original model, but will do so with an ever increasing
number of user labeled masks (the ones you have created). Eventually you
will either loose hope or find that Cellpose‚Äôs prediction become good
enough for you to be üòª!</p>
<p>Once you are happy with the results you are getting, apply your final
model to the test data we have segmented at the start of the exercise
(importantly: your model has not previously seen this image during
finetuning! Why is this important again?). Is the result better than
with the initial model you started with?</p>
</section>
<section id="using-the-image-restoration-functions">
<h3>Using the image restoration functions<a class="headerlink" href="#using-the-image-restoration-functions" title="Link to this heading">#</a></h3>
<p>Cellpose also has some ability to restore images by denoising and deblurring.
This is used to aid the segmentation of noisy data. Let‚Äôs  test it!</p>
<p>From the folder you downloaded earlier, open the ‚Äúnoisy‚Äù folder and open ‚Äúconvollaria.tif‚Äù
in cellpose.</p>
<p>Try using the Cyto3 model to segment this image (you can leave the diameter at 30 pixels).</p>
<p>Not a very satisfying result is it?</p>
<p>This is partially because the data is very noisy. Let‚Äôs try to add some denoising befre we segment.</p>
<p>Under ‚ÄúImage restoration, press the ‚Äúdenoise‚Äù button. What do you notice about the image?</p>
<p>Try using the same parameters and mode to segment this image. Did it improve?</p>
<p>Try some other restoration modes. Try using some custom filters and see if you can improve the
segmentation. What might be useful for denoising this image?</p>
</section>
</section>
<section id="exercise-3-first-steps-with-google-colab-dont-waste-too-much-time-here">
<h2><strong>Exercise 3: First steps with Google Colab (don‚Äôt waste too much time here‚Ä¶)</strong><a class="headerlink" href="#exercise-3-first-steps-with-google-colab-dont-waste-too-much-time-here" title="Link to this heading">#</a></h2>
<p>The following steps should get you started in no time:</p>
<ol class="arabic">
<li><p>Please go to
<a class="reference external" href="https://drive.google.com"><u>https://drive.google.com</u></a> and log
in with your google account. If you do not have (and do not want
one), please team up with somebody else who has one(or is willing to
create one).</p></li>
<li><p>If you never used Google Colab:</p>
<ul class="simple">
<li><p>click on
<img alt="_images/image9.png" src="_images/image9.png" />&gt;
More &gt; Connect more apps</p></li>
<li><p>search for ‚ÄúColaboratory‚Äù and connect it to your google account</p></li>
</ul>
</li>
<li><p>You should now see a new folder in your google drive:</p>
<ul>
<li><img alt="_images/image12.png" src="_images/image12.png" />
</li>
</ul>
</li>
</ol>
<p>Now let‚Äôs look at some existing tutorial notebook and play a bit with
it:</p>
<ol class="arabic simple">
<li><p>Open
<a class="reference external" href="https://colab.research.google.com/notebooks/intro.ipynb"><u>https://colab.research.google.com/notebooks/intro.ipynb</u></a>
and try to execute the few code cells you‚Äôll find there.</p></li>
<li><p>Now open a linear regression example available online and follow it
until (and including) the section ‚ÄúSimple Linear Regression‚Äù.<br />
Don‚Äôt waste your time today to go any further‚Ä¶ it is of course super
interesting, but totally out of scope‚Ä¶ ;)<br />
<a class="reference external" href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.06-Linear-Regression.ipynb"><u>https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.06-Linear-Regression.ipynb</u></a></p></li>
</ol>
<blockquote>
<div><p><em>Credit:</em><img alt="_images/image5.png" src="_images/image5.png" /></p>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p><em>Note:</em> you can save your own copy of this notebook on your own
Google Drive via‚Ä¶<br />
<img alt="_images/image17.png" src="_images/image17.png" /></p></li>
</ol>
</section>
<section id="exercise-4-first-steps-with-zerocostdl4mic">
<h2><strong>Exercise 4: First steps with ZeroCostDL4Mic</strong><a class="headerlink" href="#exercise-4-first-steps-with-zerocostdl4mic" title="Link to this heading">#</a></h2>
<p>ZeroCostDL4Mic<span id="id2">[<a class="reference internal" href="bibliography.html#id10" title="Lucas von Chamier, Romain F Laine, Johanna Jukkala, Christoph Spahn, Daniel Krentzel, Elias Nehme, Martina Lerche, Sara Hern√°ndez-P√©rez, Pieta K Mattila, Eleni Karinou, S√©amus Holden, Ahmet Can Solak, Alexander Krull, Tim-Oliver Buchholz, Martin L Jones, Lo√Øc A Royer, Christophe Leterrier, Yoav Shechtman, Florian Jug, Mike Heilemann, Guillaume Jacquemet, and Ricardo Henriques. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat. Commun., 12(1):2276, April 2021.">5</a>]</span> is a collection of (hopefully) self-explanatory Jupyter
Notebooks for Google Colab. They are meant to quickly get you started on
learning how to use deep-learning methods specifically created for
microscopy image analysis.</p>
<p>Google Colab itself provides the computations resources needed and does
so at zero cost. ZeroCostDL4Mic is designed for researchers that have
little or no coding expertise to quickly test, train and use popular
neural networks approaches.</p>
<ol class="arabic">
<li><p>Go to
<a class="reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki"><u>https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki</u></a></p></li>
<li><p>Scroll down and be amazed by the amount of available methods‚Ä¶ ;)</p></li>
<li><p>You could pick any method now and start playing with‚Ä¶ but‚Ä¶ why not
start with ‚ÄúNoise2Void (2D)‚Äù?<br />
<img alt="_images/image18.png" src="_images/image18.png" /><br />
Find it, download any example data, then click on ‚ÄúOpen in Colab‚Äù.
(Hint: the sample data can also be found behind the ‚ÄúLab Data‚Äù link
above‚Ä¶)</p></li>
<li><p>You will find yourself at a page looking roughly like this:<br />
<img alt="_images/image10.png" src="_images/image10.png" /></p></li>
<li><p>In order to work on your own data (or also on the test data we
downloaded just before), please upload it on your Google Drive (in
any folder you‚Äôd like).</p></li>
<li><p>While uploading, you can start going through the Noise2Void notebook
we opened before.</p>
<p>a.  At some point (at Step 2.2) you will be asked to connect to your
Google Drive. Please do so! üôÇ</p>
<p>b.  Note that you will now see the content of your google drive.
Click first on the ‚ÄúFiles‚Äù icon, then go one folder up, and you
should see something like this:
<img alt="_images/image19.png" src="_images/image19.png" /></p>
<p>c.  <strong>DONE!</strong> Let‚Äôs continue in the next exercise‚Ä¶</p>
</li>
</ol>
</section>
<section id="exercise-5-image-denoising-with-noise2void-in-zero">
<h2><strong>Exercise 5: Image Denoising with Noise2Void (in ‚ÄúZero‚Äù)</strong><a class="headerlink" href="#exercise-5-image-denoising-with-noise2void-in-zero" title="Link to this heading">#</a></h2>
<p>In this exercise we will denoise some data with Noise2Void. Please
remember, Noise2Void is removing pixel-noises only (Poisson noise,
readout noise, etc.).</p>
<p>If you do not have really noisy data at hand, feel free to use the
example data offered on the ZeroCostDL4Mic wiki (or from within the Lab
Data link from above, or just use
<a class="reference external" href="https://tinyurl.com/DLLab-droso2d"><u>https://tinyurl.com/DLLab-droso2d</u></a>).
Ideally, as a group we use a bunch of different datasets, so we have
more results to look at‚Ä¶</p>
<img alt="_images/image16.png" src="_images/image16.png" />
<ol class="arabic">
<li><p>Decide what data to use (see remarks above).</p></li>
<li><p>Copy the data to any sensible place on your Google Drive.<br />
(<em>Why? Data on Google Drive can be read easily and FAST by Collab‚Ä¶</em>)</p></li>
<li><p>Start the Noise2Void Colab Notebook from Zero (likely you did that
already in the last exercise, didn‚Äôt you?).</p></li>
<li><p>Go through the notebook. The first time around this will take a
while and be confusing at times. Plow through it, you will soon be
happy!<br />
<strong>Ask questions, help each other!</strong></p>
<p>a.  <em>Pro tip:</em> if you are in a hurry, reduce the number of epochs to
some small number, e.g. 10 or 20. Results will be much worse,
but you can always crank that number up later‚Ä¶</p>
<p>b.  Later today, when you are done with the exercises, you might
want to re-run your favorite notebook with the suggested number
of epochs. Collab will work while you have fun on your free
evening‚Ä¶ üôÇ</p>
</li>
</ol>
</section>
<section id="bonus-exercise-use-fijis-noise2void-plugin">
<h2><strong>Bonus Exercise: Use Fiji‚Äôs Noise2Void Plugin</strong><a class="headerlink" href="#bonus-exercise-use-fijis-noise2void-plugin" title="Link to this heading">#</a></h2>
<p>In this exercise you will use a Noise2Void plugin in Fiji. You will have
to install it first.</p>
<ol class="arabic">
<li><p>Open Fiji.</p></li>
<li><p>Go to Help - Update‚Ä¶ - Manage update sites, then check the CSBDeep
update site and say Close - Apply changes.</p></li>
<li><p>Restart Fiji.</p></li>
<li><p>Download
<a class="reference external" href="https://tinyurl.com/DLLab-droso2d"><u>https://tinyurl.com/DLLab-droso2d</u></a>
and open this 2D+t tiff in Fiji.</p></li>
<li><p>Start the ‚ÄúN2V train + predict‚Äù plugin.</p></li>
<li><p>Figure it out‚Ä¶ üòâ</p>
<p>a.  <em><strong>Please ask question at ANY time</strong>!</em></p>
</li>
<li><p>If all works out ok, you will see something like‚Ä¶<br />
<img alt="_images/image7.png" src="_images/image7.png" /></p></li>
<li><p>The training will likely be VERY slow, but to sweeten up the wait,
we show you a nice preview.</p></li>
<li><p>Together with the result you also get the trained model for later
reuse.<img alt="_images/image121.png" src="_images/image121.png" /></p></li>
<li><p>Try to use the trained model to denoise the same stack or any other image of your choosing.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Be sure to set the axes correctly. On the same stack, this will require you to add a third dimension which contains multiple time points. What should we use as the third axis and why is it ‚ÄòB‚Äô when you use the same stack you used for training?</p>
</div>
</li>
</ol>
</section>
<section id="bonus-exercise-image-segmentation-with-stardist-in-zero">
<h2><strong>Bonus Exercise: Image Segmentation with StarDist (in ‚ÄúZero‚Äù)</strong><a class="headerlink" href="#bonus-exercise-image-segmentation-with-stardist-in-zero" title="Link to this heading">#</a></h2>
<p>Now that you have experienced how to use ZeroCostDL4Mic Collab
notebooks, switch it up, do some instance segmentation! We suggest the
StarDist notebook, but if you feel adventurous, choose something else
you find most interesting in the context of your own research.</p>
<img alt="_images/image15.png" src="_images/image15.png" />
<p>Go through the notebook you chose. And again:</p>
<p><strong>Ask questions, help each other</strong>!</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Reduce the number of epochs to some small number to save yourself long waiting times!</p>
</div>
<p>Later today, when you are done with the exercises, you might want to re-run your favorite notebook with the suggested number of epochs.
Collab will work while you have fun on your free evening‚Ä¶ üôÇ</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Lab04_ML-based_Segmentation_and_Classification.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Segmentation and Pixel Classification</p>
      </div>
    </a>
    <a class="right-next"
       href="Lab06_3D_Image_Analysis.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">3D Image Analysis</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview"><strong>Overview</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1-remind-yourself-about-what-weve-heard-in-the-lecture"><strong>Exercise 1: Remind yourself about what we‚Äôve heard in the lecture</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-play-with-cellpose"><strong>Exercise 2: Play with CellPose</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#human-in-the-loop-retraining">Human-in-the-loop retraining</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-the-image-restoration-functions">Using the image restoration functions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-first-steps-with-google-colab-dont-waste-too-much-time-here"><strong>Exercise 3: First steps with Google Colab (don‚Äôt waste too much time here‚Ä¶)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-4-first-steps-with-zerocostdl4mic"><strong>Exercise 4: First steps with ZeroCostDL4Mic</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-5-image-denoising-with-noise2void-in-zero"><strong>Exercise 5: Image Denoising with Noise2Void (in ‚ÄúZero‚Äù)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bonus-exercise-use-fijis-noise2void-plugin"><strong>Bonus Exercise: Use Fiji‚Äôs Noise2Void Plugin</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bonus-exercise-image-segmentation-with-stardist-in-zero"><strong>Bonus Exercise: Image Segmentation with StarDist (in ‚ÄúZero‚Äù)</strong></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By QI 2024
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>